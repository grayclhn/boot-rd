\documentclass[12pt,fleqn]{article}

% Add commit information from Git to the pdf. It is automatically
% generated with the R script 'tex/git and can be run from
% the command line in the project's top directory via:
%
% $ tex/git
%
% If VERSION.tex does not exist we can't add information from
% Git, so we'll use today's date as a fallback.

\IfFileExists{../VERSION.tex}{\input{../VERSION}}{%
\providecommand\VERSION{\today}}

\input{../tex/setup}
\input{../tex/macros}

\title{Reply to the report by Referee 2 for ``Bootstrap Confidence Intervals for Sharp Regression Discontinuity Designs
  with the Uniform Kernel''}

\author{Ot\'avio Bartalotti \and Gray Calhoun \and Yang He\thanks{%
  All authors: Department of Economics, Iowa State University.
  260 Heady Hall, Ames, IA 50011.
  Bartalotti: \protect\url{bartalot@iastate.edu};
  Calhoun: \protect\url{gcalhoun@iastate.edu} and
  \protect\url{http://gray.clhn.org};
  He: \protect\url{yanghe@iastate.edu}.}}

\begin{document}
\maketitle

First, we thank the reviewer for providing detailed and helpful comments, which
we feel have significantly improved the quality of the draft.  Below we provide
replies to the reviewer's specific comments detailing how we address each
comment.

\section{General overview of changes}

For this version of the paper, we have changed the bootstrap method from the
residual bootstrap to the wild bootstrap. We have also updated the simulations
to include DGPs featuring heteroskedasticity. We believe that the residual
bootstrap used in the previous version is theoretically correct even under
heteroskedastcity as long as the conditional variance is assumed to be smooth in
a neighborhood around the cutoff point, since the residual bootstrap we initially
proposed only resampled from that neighborhood, but we agree that in practice
the wild bootstrap is likely to be more accurate and can accommodate forms of
conditional heteroskedasticity that the residual bootstrap can not.

We have also relaxed the ``uniform kernel'' requirement and allow other kernels
that are popular in practice. The title of the paper has been updated to reflect
that change.

The first referee expressed concern about the possible computational complexity of
using an iterated bootstrap to produce confidence intervals. This is much less
of an issue than it appears, because many of the matrix calculations can be
computed once and then reused in the bootstrap replications. (Any calculation
that does not involve $Y$ can be reused.) Each bootstrap replication only
requires a small number of matrix-vector multiplications which can be completed
very quickly. We have added a short section after Algorithm 2 that explains
this implementation detail, and we have also provided open source R code that
implements the procedure efficiently.

Finally, the mathematical appendix defines more notation explicitly and
summarizes several convergence results from Calonico, Cattaneo, and Titiunik
(2014) that are referenced in the proofs and we have made some small additional
changes that the referees suggested.

\section{Specific Comments}

\begin{enumerate}

 \item  \textit{``Page 4 line 4: ``can be accommodated''.''}

 Thanks. This has been fixed.

\item \textit{``Although standard in the RDD literature, it will be useful to distinguish conditions for identification from those for estimation and inference. Most of Assumption 1 is for
estimation and inference, and I suggest adding a short discussion there to explain each component of Assumption 1, and make it clear which are essential for identification. ''}

 Thanks. A short discussion has been added to the main text.
  

\item \textit{`` To match the notation used in Calonico et al. (2014), I suggest to define $V(h) :=\V[\hat{\tau}(h)|X_{1}, \dots ,X_{n}]$, and use $\hat{V}(h)$ when constructing confidence intervals. See the definition of $V_{SRD}(h_{n})$ in Calonico et al. (2014).''}

 Thank you for the recommendation. Adjustments were made in the draft.

\item \textit{``By assuming the bandwidth condition $b \geq h, nb \rightarrow \infty$ is redundant. Moreover, the bandwidth condition in Theorem 1 of Calonico et al. (2014) reduces to $nh^{5}b^{2} \rightarrow 0$. This paper assumes, additionally, that $nb^{5}h^{2} \rightarrow 0$. It is not clear why the extra condition is needed, and I recommend adding some discussion/explanation.''}

  Thanks for bringing this up. In the general kernel setup developed for this draft it became clear that the condition $h<b$ is not necessary and it has been dropped. Regarding the conditions $nh^{5}b^{2} \rightarrow 0$ and $nb^{5}h^{2} \rightarrow 0$, we originally decided to present the conditions in this form to make it more accessible to the readers. Note that CCT Theorem 1 assumes $n \min\{h^{5},b^{5}\}\max\{h^{2}, b^{2}\} \rightarrow 0$ which is equivalent to our condition now that $b < h$ is allowed.


\item \textit{``Calonico et al. (2014) allow $h/b \rightarrow \rho \in [0,\infty]$, while the assumption used in this paper requires $h/b \leq 1$. It is mentioned in footnote 12 that the condition $h \leq b$ can be generalized with other kernels. Please provide more intuition, and to what extent it can be relaxed.''}

Please see the discussion to about the relationship between $h$ and $b$ in the previous comment.

\item \textit{``Use $\mathbb{P}$ instead of Pr.''}

No problem.

\item \textit{``In Algorithm 1, use $\Delta(h,b)$ or $\hat{\Delta}(h,b)$ instead of $\Delta^{*}(h,b)$, as there is no bootstrap uncertainty in the estimated bias. Accordingly in Algorithm 2, use $\Delta^{*}(h,b)$ or $\hat{\Delta}^{*}(h,b)$ instead of $\Delta^{**}(h,b)$.''}

We're not sure that we understand this comment---there is definitely bootstrap
uncertainty in the estimated bias in our procedure because we estimate the
bias with a preliminary bootstrap. We ignore this uncertainty in the theoretical
results (which is consistent with the bootstrap literature) but it will be
present in applications.

\item \textit{``In Algorithm 2.1, it should be ``$\hat{g}_{-}$ and $\hat{g}_{+}$''.''}
 
 Thanks. It has been corrected.

\item \textit{``Instead of $\hat{\tau}'(h,b)$ and $V'(h,b)$, I recommend using $\hat{\tau}^{bc}(h,b)$ and $V^{bc}(h,b)$ to make the notation more explicit.''}

Thanks for the suggestion. We have changed this in the paper.

\item \textit{``In Algorithm 1.2(b) and Algorithm 2.2(b), it should be $X_{i}$ rather than $X^{*}_{i}$.''}
 
Thanks. It is now fixed.

\item \textit{``In Section 4 (Simulation Evidence), the Naive Bootstrap is implemented with nonparametric resampling and the bandwidth is re-calculated for each bootstrap repetition.
This is quite different from the other procedures, and can be misleading. I recommend not including the Naive Bootstrap.''}

Thank you for the recommendation. We dropped the Naive Bootstrap from the Simulation Evidence.

\item \textit{``As mentioned earlier, the wild bootstrap seems to be more appealing in terms of finite sample performance when the variance $\sigma^{2}(x)$ varies near the cutoff. The algebra should not be difficult and I recommend the authors to include theoretical results with the wild bootstrap.''}

Thanks, we've made this change as discussed above.

\item \textit{``It will be helpful to have simulation results for DGPs with heteroskedastic variance.''}

  Thank you for this suggestion; we have added additional simulations with conditional heteroskedasticity.

\item \textit{``In the Mathematical Appendix, the authors used min(h, b), which is redundant. (Page 19, line 4-5)''}

Thanks for pointing this out. It is no longer redundant since we have relaxed
the requirement that $h < b$.

\item \textit{``The Mathematical Appendix should contain more details.''}

Thank you for pointing this out. We have added much more exposition to the
Mathematical Appendix.

\end{enumerate}


\end{document}